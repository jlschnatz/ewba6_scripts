[
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "EW-BA6",
    "section": "",
    "text": "Nachdem wir im ersten Skript gelernt haben, wie man einen Beispieldatensatz für die Analyse vorbereitet, beschäftigen wir uns nun mit den Möglichkeiten der statistischen Auswertung. Wir setzen direkt am bisherigen Beispiel an und führen euch Schritt für Schritt durch die wichtigsten Methoden der deskriptiven und inferenzstatistischen Analyse."
  },
  {
    "objectID": "analysis.html#kategorische-variablen",
    "href": "analysis.html#kategorische-variablen",
    "title": "EW-BA6",
    "section": "Kategorische Variablen",
    "text": "Kategorische Variablen\nFür die Beschreibung von kategorialen Variablen sind absolute und relative Häufigkeiten zentral. Sie zeigen, wie viele Personen in jeder Gruppe sind und wie groß ihr Anteil an der Gesamtstichprobe ist. In R können wir dafür den freq_table() aus dem Paket rstatix nutzen.\n\ntab_df(freq_table(data_proc, geschlecht), col.header = c(\"Geschlecht\", \"N\", \"Relative Häufigkeit\"))\n\n\n\n\nGeschlecht\nN\nRelative Häufigkeit\n\n\nm\n32\n23.50\n\n\nw\n103\n75.70\n\n\nd\n1\n0.70\n\n\n\n\n\nAuch für Kombinationen mehrerer Kategorien (z.B. Geschlecht und Verfügbarkeitserwartung) ist dies möglich.\n\ntab_df(freq_table(data_proc, geschlecht, verfuegbarkeitserwartung), col.header = c(\"Geschlecht\", \"Verfügbarkeitserwartung\", \"N\", \"Relative Häufigkeit\"))\n\n\n\n\nGeschlecht\nVerfügbarkeitserwartung\nN\nRelative Häufigkeit\n\n\nm\nniedrig\n12\n37.50\n\n\nm\nmittel\n12\n37.50\n\n\nm\nhoch\n8\n25.00\n\n\nw\nniedrig\n25\n24.30\n\n\nw\nmittel\n47\n45.60\n\n\nw\nhoch\n31\n30.10\n\n\nd\nmittel\n1\n100.00"
  },
  {
    "objectID": "analysis.html#numerische-variablen",
    "href": "analysis.html#numerische-variablen",
    "title": "EW-BA6",
    "section": "Numerische Variablen",
    "text": "Numerische Variablen\nNumerische Variablen wie „Alter“ oder „FOMO“ werden mit statistischen Kennwerten wie Mittelwert (Durchschnitt), Standardabweichung (Streuung), Median (Zentralwert) und weiteren beschrieben (s.h. Folien). Diese Kennwerte geben einen schnellen Überblick über die Verteilung der Daten.\nIn R nutzen wir dafür die get_summary_stats() Funktion.\n\ntab_df(get_summary_stats(select(data_proc, c(alter, fomo)), type = \"common\"))\n\n\n\n\nvariable\nn\nmin\nmax\nmedian\niqr\nmean\nsd\nse\nci\n\n\nalter\n136\n18.00\n39.00\n21.00\n2.00\n21.65\n3.44\n0.29\n0.58\n\n\nfomo\n136\n1.26\n3.46\n2.43\n0.59\n2.41\n0.42\n0.04\n0.07\n\n\n\n\n\nMit dem Argument type kann festgelegt werden, welche Kennwerte angezeigt werden sollen. Weitere Informationen liefert help(get_summary_stats).\n\ndata_proc %&gt;%\n   select(fomo, verfuegbarkeitserwartung) %&gt;% # relevante Variablen selektieren\n   group_by(verfuegbarkeitserwartung) %&gt;% # Gruppierung nach kategorieller Variable\n   get_summary_stats(type = \"mean_sd\") %&gt;% # Mittelwert und Standardabweichung\n   select(-variable) %&gt;%\n   tab_df(col.header = c(\"Verfügbarkeitserwartung\", \"N\", \"M\", \"SD\"), digits = 1) # Rundung auf eine Nachkommastelle\n\n\n\n\nVerfügbarkeitserwartung\nN\nM\nSD\n\n\nniedrig\n37\n2.3\n0.4\n\n\nmittel\n60\n2.3\n0.4\n\n\nhoch\n39\n2.7\n0.4"
  },
  {
    "objectID": "analysis.html#korrelationen",
    "href": "analysis.html#korrelationen",
    "title": "EW-BA6",
    "section": "Korrelationen",
    "text": "Korrelationen\nWenn wir untersuchen möchten, ob zwei Variablen systematisch miteinander zusammenhängen, also ob sie gemeinsam kovariieren, nutzen wir die Korrelation als Maß für die Richtung und Stärke des Zusammenhangs. Im vorliegenden Beispiel interessiert uns, ob das Alter mit dem FOMO-Wert negativ zusammenhängt – also ob ältere Personen geringere FOMO-Werte aufweisen.\nHypothesenformulierung:\nWir gehen in diesem Fall also von einem gerichteten Zusammenhang aus:\n\nNullhypothese (\\(\\mathcal{H}_0\\)): Es besteht kein negativer Zusammenhang zwischen Alter und FOMO, also \\(r \\geq 0\\).\nAlternativhypothese (\\(\\mathcal{H}_1\\)): Es besteht ein negativer Zusammenhang, also \\(r &lt; 0\\).\n\nVisuelle Überprüfung\nBevor wir den Zusammenhang statistisch testen, empfiehlt sich eine grafische Exploration der Daten. Ein Streudiagramm zeigt, wie die einzelnen Werte von Alter und FOMO verteilt sind und ob ein Trend sichtbar ist. Zusätzlich wird eine Regressionslinie eingeblendet, die den geschätzten linearen Zusammenhang visualisiert.\n\ntidyplot(data_proc, x = alter, y = fomo) %&gt;%\n   add_data_points_jitter(jitter_width = 0.6, white_border = TRUE) %&gt;%\n   add_curve_fit(method = \"lm\", linewidth = 0.9, alpha = 0.2) %&gt;%\n   adjust_font(family = \"Optima\", fontsize = 11) %&gt;%\n   adjust_y_axis(limits = c(1, 5), breaks = seq(1, 5)) %&gt;% \n   adjust_x_axis_title(\"Alter\") %&gt;%\n   adjust_y_axis_title(\"FOMO\") %&gt;%\n   adjust_size(width = NA, height = NA)\n\n\n\n\n\n\n\n\nDie Grafik ermöglicht es, erste Hinweise auf die Richtung und Form des Zusammenhangs zu erhalten. Der abfallender Verlauf der Regressionslinie legt einen negativen Zusammenhang nahe.\nStatistische Prüfung:\nFür die Berechnung des Zusammenhangs verwenden wir den Pearson-Korrelationskoeffizienten, da beide Variablen metrisch sind und ein linearer Zusammenhang angenommen wird. Die gerichtete Hypothese wird durch das Argument alternative = \"less\" umgesetzt:\n\nr_fomo_alter &lt;- cor_test(\n   data = data_proc,       # Datensatz\n   vars = c(fomo, alter),  # Variablen\n   method = \"pearson\",     # Pearson-Korrelation\n   alternative = \"less\"    # Gerichterer Zusammenhang H1: r &lt; 0\n   ) \n\ntab_df(r_fomo_alter)\n\n\n\n\nvar1\nvar2\ncor\nstatistic\np\nconf.low\nconf.high\nmethod\n\n\nfomo\nalter\n-0.29\n-3.55\n0.00\n-1\n-0.16\nPearson\n\n\n\n\n\nInterpretation:\n\nDer Korrelationskoeffizient \\(r\\) gibt Richtung und Stärke des Zusammenhangs an. Ein negativer Wert bestätigt die Hypothese, dass mit steigendem Alter der FOMO-Wert sinkt\nDer p-Wert zeigt die Wahrscheinlichkeit, unter der Nullhypothese (\\(r \\geq 0\\)) einen mindestens so starken negativen Zusammenhang zu beobachten. Ist der p-Wert kleiner als das Signifikanzniveau (z.B. \\(\\alpha = .05\\)), wird die Nullhypothese verworfen und die gerichtete Alternativhypothese angenommen\n\nAlternative: Spearman-Korrelation:\nWenn die Voraussetzungen für Pearson (Normalverteilung, Linearität) nicht erfüllt sind, kann die Spearman-Rangkorrelation verwendet werden.\n\ncor_test(data_proc, fomo, alter, method = \"spearman\", alternative = \"less\")  %&gt;%\n   tab_df()\n\n\n\n\nvar1\nvar2\ncor\nstatistic\np\nmethod\n\n\nfomo\nalter\n-0.22\n512148.95\n0.00\nSpearman"
  },
  {
    "objectID": "analysis.html#mittelwertsvergleiche",
    "href": "analysis.html#mittelwertsvergleiche",
    "title": "EW-BA6",
    "section": "Mittelwertsvergleiche",
    "text": "Mittelwertsvergleiche\nMittelwertsvergleiche dienen dazu, festzustellen, ob sich die durchschnittlichen Werte einer metrischen Variablen (z.B. FOMO) zwischen zwei oder mehr Gruppen signifikant unterscheiden. Die Wahl des statistischen Tests hängt davon ab, wie viele Gruppen miteinander verglichen werden sollen.\n\nt-Test\nDer t-Test für unabhängige Stichproben prüft, ob sich die Mittelwerte zweier unabhängiger Gruppen signifikant unterscheiden. In unserem Beispiel interessiert uns, ob Personen unterschiedlichen Geschlechts (männlich vs. weiblich) unterschiedliche FOMO-Werte aufweisen.\nHypothesenformulierung\n\nNullhypothese (\\(\\mathcal{H}_0\\)): Die Mittelwerte der beiden Gruppen sind gleich (\\(\\mu_\\text{m} = \\mu_\\text{w}\\)).\nAlternativhypothese (\\(\\mathcal{H}_1\\)): Die Mittelwerte unterscheiden sich (\\(\\mu_\\text{m} \\neq \\mu_\\text{w}\\)).\n\nZur Vorbereitung müssen wir in unserem Fall einen Subdatensatz erstellen, indem nur die beiden Geschlechter männlich und weiblich enthalten sind. Die eine Person, die sich als divers identifiziert, können wir aufgrund der geringen Stichprobengröße nicht in unsere statistische Analyse aufnehmen.\n\ntable(data_proc$geschlecht)\n\n\n  m   w   d \n 32 103   1 \n\ndata_ttest &lt;- subset(data_proc, subset = (geschlecht == \"m\" | geschlecht == \"w\"))\ndata_ttest$geschlecht &lt;- droplevels(data_ttest$geschlecht)\nlevels(data_ttest$geschlecht)\n\n[1] \"m\" \"w\"\n\n\nVisuelle Exploration\nVor der formalen Testung empfiehlt sich eine grafische Darstellung der Verteilungen und Mittelwerte in beiden Gruppen, um ein Gefühl für die Daten zu bekommen. Hierzu eignet sich beispielsweise ein Dichteplot mit eingezeichneten Mittelwerten und den Rohdatenpunkten. Ein Dichteplot zeigt, wie die Werte einer Variablen innerhalb einer Gruppe verteilt sind, und macht sichtbar, ob die Verteilung beispielsweise symmetrisch, schief oder mehrgipflig ist.\n\ntidyplot(data_ttest, x = geschlecht, y = fomo, color = geschlecht) %&gt;%\n   add_ci95_errorbar(width = 0.0, linewidth = 1) %&gt;%\n   add_mean_dot(width = 1) %&gt;%\n   add_data_points_jitter(alpha = 0.1, jitter_width = 0.1) %&gt;%\n   remove_legend() |&gt;\n   adjust_font(family = \"Optima\", fontsize = 11) %&gt;%\n   adjust_y_axis(limits = c(1, 5), breaks = seq(1, 5)) %&gt;% \n   adjust_x_axis_title(\"Geschlecht\") %&gt;%\n   adjust_y_axis_title(\"FOMO\") %&gt;%\n   adjust_size(width = NA, height = NA) %&gt;%\n   #add_test_asterisks(method = \"t_test\", hide.ns = FALSE, hide_info = TRUE) |&gt;\n   add_test_pvalue(label = \"italic(p) = {format_p_value(p, 0.001)}\", hide_info = TRUE)\n\n\n\n\n\n\n\n\nDiese Darstellung erlaubt es, die Verteilung, Streuung und Lage der Mittelwerte in beiden Gruppen direkt zu vergleichen.\nVoraussetzungen des t-Tests\nVor der Durchführung des t-Tests sollten die Voraussetzungen geprüft werden:\n\nNormalverteilung der abhängigen Variable in beiden Gruppen (z.B. Shapiro-Wilk-Test).\nVarianzhomogenität (Gleichheit der Varianzen, z.B. Levene-Test).\nUnabhängigkeit der Beobachtungen (durch Studiendesign gegeben).\n\nWir können die Voraussetzungen der Normalverteilungen beispielsweise mit einem Shapiro-Test überprüfen. Wenn der p-Wert nicht statistisch signifikant ist, behalten wir die Nullhypothese, dass die Daten in der Population normalverteilt sind bei.\n\ndata_ttest %&gt;%\n   group_by(geschlecht) %&gt;%\n   shapiro_test(fomo)\n\n\n  \n\n\n\nBeide p-Werte aus dem Shapiro-Wilk-Test sind in diesem Beispiel nicht statistisch signifikant, das bedeutet, dass wir die Nullhypothese der Normalverteilung beibehalten und davon ausgehen können, dass die Normalverteilungsannahme für die FOMO-Werte in beiden Geschlechtsgruppen nicht verletzt ist.\nDie Annahme der Varianzhomogenität (Homoskedastizität) überprüfen wir mit dem Levene-Test. Auch hier gilt: Die Nullhypothese des Tests besagt, dass die Varianzen in den Gruppen gleich sind. Ein nicht signifikanter p-Wert spricht dafür, dass kein Hinweis auf einen Unterschied der Varianzen vorliegt, sodass wir die Homoskedastizitätsannahme als erfüllt ansehen können.\n\nlevene_test(data_ttest, fomo ~ geschlecht)\n\n\n  \n\n\n\nDa auch der Levene-Test in diesem Beispiel einen nicht signifikanten p-Wert liefert, gehen wir davon aus, dass die Voraussetzung der Varianzhomogenität nicht verletzt ist. Damit sind die zentralen Voraussetzungen für die Durchführung eines t-Tests für unabhängige Stichproben erfüllt\nStatistischer Test\n\ntt_geschl_fomo &lt;- t_test(\n   data = data_ttest,            # Datensatz\n   formula = fomo ~ geschlecht,  # Formel\n   alternative = \"two.sided\",    # zweiseitiger Test (H0: m1 - m2 = 0)\n   paired = FALSE,               # Test für unabhängige Stichproben\n   ref.group = \"w\",               # Referenzgruppe: w - m\n   detailed = TRUE\n   )\n\ntab_df(tt_geschl_fomo)\n\n\n\n\nestimate\nestimate1\nestimate2\n.y.\ngroup1\ngroup2\nn1\nn2\nstatistic\np\ndf\nconf.low\nconf.high\nmethod\nalternative\n\n\n0.08\n2.42\n2.34\nfomo\nw\nm\n103\n32\n1.09\n0.28\n59.96\n-0.07\n0.24\nT-test\ntwo.sided\n\n\n\n\n\n\nt-Wert: Teststatistik, die das Verhältnis des Mittelwertsunterschieds zur Streuung beschreibt.\nFreiheitsgrade (df): Anzahl der unabhängigen Informationen.\np-Wert: Gibt an, wie wahrscheinlich ein mindestens so großer Unterschied unter der Nullhypothese ist.\n\nWir sehen, dass weibliche Personen im Mittel einen 0.08 Punkte größere FOMO Wert auweisen als männliche Personen. Der dazugehörige t-Wert von t(59)=1.09 ist mit einem p-Wert von p = 0.282 mit einem \\(\\alpha\\)-Niveaus von 5% statistisch nicht bedeutsam. Wir können also die Nullhypothese, dass der FOMO Mittelwert von männlichen und weiblichen Perosnen sich unterscheiden, nicht verwerfen.\nWichtig ist jedoch zu betonen, dass ein nicht signifikanter p-Wert nicht automatisch bedeutet, dass die Mittelwerte in der Population tatsächlich gleich sind. Die Schlussfolgerung, dass Gleichheit besteht, ist statistisch nicht zulässig, da ein Hypothesentest bei nicht signifikantem Ergebnis lediglich anzeigt, dass die Daten keinen ausreichenden Beleg für einen Unterschied liefern – er kann jedoch nicht bestätigen, dass tatsächlich kein Unterschied existiert.\nEffektstärke: Cohen’s d\nDie Effektstärke gibt die praktische Relevanz des Unterschieds an. Cohen’s d ist ein standardisiertes Maß für den Mittelwertsunterschied:\n\ncohens_d(data_ttest, fomo ~ geschlecht) %&gt;% tab_df()\n\n\n\n\n.y.\ngroup1\ngroup2\neffsize\nn1\nn2\nmagnitude\n\n\nfomo\nm\nw\n-0.21\n32\n103\nsmall\n\n\n\n\n\n\n\\(d = 0.2\\) –  kleiner Effekt\n\\(d = 0.5\\) – mittlerer Effekt\n\\(d = 0.8\\) – großer Effekt\n\nEine Effektstärke von d = -0.21 bedeutet, dass sich die beiden Gruppen im Mittel um -0.21 Standardabweichungen unterscheiden. Es ist hier also maximal von einem kleinem Effekt auszugehen.\n\n\nANOVA\nWenn mehr als zwei Gruppen verglichen werden sollen, verwendet man die Varianzanalyse (ANOVA). Sie prüft, ob sich mindestens ein Gruppenmittelwert signifikant von den anderen unterscheidet.\nHypothesenformulierung\n\nNullhypothese (\\(\\mathcal{H}_0\\)): Alle Gruppenmittelwerte sind gleich (\\(\\mu_1 = \\mu_2 = \\mu_3\\)).\nAlternativhypothese (\\(\\mathcal{H}_1\\)): Mindestens ein Gruppenmittelwert unterscheidet sich.\n\nVisuelle Exploration\nAuch hier empfiehlt sich eine grafische Darstellung der Verteilung der FOMO-Werte in den verschiedenen Gruppen (z.B. nach Verfügbarkeitserwartung):\n\ntidyplot(\n   data = data_proc, \n   x = verfuegbarkeitserwartung, \n   y = fomo, \n   color = verfuegbarkeitserwartung\n   ) %&gt;%\n   add_boxplot(box_width = 0.2, whiskers_width = 0) %&gt;%\n   add_test_pvalue(\n      method = \"tukey_hsd\", \n      p.adjust.method = \"fdr\",\n      label = \"italic(p) = {format_p_value(p.adj, 0.001)}\", \n      hide_info = TRUE\n   ) %&gt;%\n   remove_legend() |&gt;\n   adjust_font(family = \"Optima\", fontsize = 11) %&gt;%\n   adjust_y_axis(limits = c(1, 5), breaks = seq(1, 5)) %&gt;% \n   adjust_x_axis_title(\"Verfügbarkeitserwartung\") %&gt;%\n   adjust_y_axis_title(\"FOMO\") %&gt;%\n   adjust_size(width = NA, height = NA) %&gt;%\n   adjust_colors(colors_discrete_metro)\n\n\n\n\n\n\n\n\nDiese Grafik zeigt die Verteilung, Streuung und Mittelwerte der FOMO-Werte in allen drei Gruppen.\nVoraussetzungen der ANOVA\n\nNormalverteilung der abhängigen Variable in allen Gruppen.\nVarianzhomogenität (Gleichheit der Fehlervarianzen).\nUnabhängigkeit der Beobachtungen.\n\nStatistischer Test\n\naov_test &lt;- anova_test(data_proc, fomo ~ verfuegbarkeitserwartung, detailed = TRUE, effect.size = c(\"ges\", \"pes\"))\nprint(aov_test)\n\nANOVA Table (type II tests)\n\n                    Effect   SSn    SSd DFn DFd      F       p p&lt;.05   pes\n1 verfuegbarkeitserwartung 4.087 19.607   2 133 13.862 3.4e-06     * 0.172\n\n\n\nF-Wert: Verhältnis der Varianz zwischen den Gruppen zur Varianz innerhalb der Gruppen.\nFreiheitsgrade (df): Anzahl der Gruppen minus eins (zwischen), Gesamtstichprobe minus Gruppenanzahl (innerhalb).\np-Wert: Gibt an, wie wahrscheinlich ein mindestens so großer Unterschied unter der Nullhypothese ist.\n\nDie ANOVA ergibt einen F-Wert von 13,86 bei 2 und 133 Freiheitsgraden. Der zugehörige p-Wert beträgt 3,4 × 10⁻⁶ und liegt damit deutlich unter dem üblichen Signifikanzniveau von 5 %. Das bedeutet, dass wir die Nullhypothese der Gleichheit der Mittelwerte ablehnen können. Es gibt also einen statistisch bedeutsamen Unterschied im durchschnittlichen FOMO-Wert zwischen mindestens zwei Stufen der Verfügbarkeitserwartung. Die partielle Eta-Quadrat (\\(\\eta^2_\\mathrm{ges}\\)) von 0,172 weist zudem auf einen mittleren Effekt hin, das heißt, ein relevanter Anteil der Gesamtvarianz der FOMO-Skala wird durch die Verfügbarkeitserwartung erklärt.\nPost-hoc-Kontraste (Tukey-Test)\nDa die ANOVA nur zeigt, dass irgendwo ein Unterschied zwischen den Gruppen besteht, führen wir zur genaueren Bestimmung der Unterschiede Post-hoc-Tests durch. Der Tukey-Test vergleicht alle möglichen Gruppenpaare miteinander und kontrolliert das Fehlerniveau für multiples Testen.\n\ntab_df(tukey_hsd(data_proc, fomo ~ verfuegbarkeitserwartung))\n\n\n\n\nterm\ngroup1\ngroup2\nnull.value\nestimate\nconf.low\nconf.high\np.adj\np.adj.signif\n\n\nverfuegbarkeitserwartung\nniedrig\nmittel\n0\n0.03\n-0.16\n0.22\n0.94\nns\n\n\nverfuegbarkeitserwartung\nniedrig\nhoch\n0\n0.40\n0.19\n0.61\n0.00\n****\n\n\nverfuegbarkeitserwartung\nmittel\nhoch\n0\n0.37\n0.18\n0.56\n0.00\n****\n\n\n\n\n\nDie Ergebnisse zeigen:\n\nZwischen den Gruppen „niedrig“ und „mittel“ besteht kein signifikanter Unterschied im FOMO-Mittelwert (p = 0.94).\nZwischen „niedrig“ und „hoch“ sowie zwischen „mittel“ und „hoch“ bestehen jeweils signifikante Unterschiede (p &lt; .001). In beiden Fällen ist der FOMO-Wert bei Personen mit hoher Verfügbarkeitserwartung im Mittel um etwa 14 Punkte höher als in den anderen Gruppen."
  },
  {
    "objectID": "preprocess.html",
    "href": "preprocess.html",
    "title": "EW-BA6",
    "section": "",
    "text": "Einleitung\nIn diesem Skript geht es um die Vorbereitungen für die Analysen, die ihr im Rahmen eurer Hausarbeit rechnen sollt. Das heißt, wir bereiten die Daten so auf, dass sie mithilfe des 2. Skripts ausgewertet werden können. Dies machen wir anhand eines Beispieldatensatzes, der eurem ähnelt und auch die gleichen Probleme und Fallstricke beinhaltet, sodass ihr im besten Fall die Skripte kopieren könnt und nur noch an eure Studien anpassen müsst.\n\n\nDaten in R laden\nAls erstes müssen die notwendigen Pakete geladen werden.\nIm zweiten Schritt müsst ihr die erhobenen Daten aus SosciSurvey in R laden, um dort mit den Daten rechnen und arbeiten zu können. Wenn man Dateien von SosciSurvey herunterlädt, liegen sie üblicherweise als .csv oder als .excel vor, hier als .csv.\nLadet den Datensatz wie im entsprechenden Video vorgestellt von SosciSurvey herunter und stellt euer Working Directory richtig ein (setwd()). Dies muss der Ordner sein, indem der Datensatz liegt (verschiebt ihn hierfür manuell aus dem Downloadordner). Danach kann der Datensatz folgendermaßen eingelesen werden read_csv().\n\n## Pakete laden:\ninstall.packages(\"dplyr\")\nlibrary(dplyr)\n\ninstall.packages(\"naniar\")\nlibrary(naniar)\n\ninstall.packages(\"psych\")\nlibrary(psych)\n\ninstall.packages(\"readr\")\nlibrary(readr)\n\ninstall.packages(\"sjmisc\")\nlibrary(sjmisc)\n\n## Abfrage und Einstellen des Working Directory:\ngetwd() # Abfrage des Working Directory\nsetwd(\"C:path/to/directory\") # Hier euren Ordner einstellen\n\n## Datensatz einladen\ndata_roh &lt;- read.csv(\"name-des-datensatzes.csv\") # Datensatz in R laden\n\n\n\nÜberblick über die Daten erhalten\nAls erstes betrachten wir, welche Variablen alle existieren. Hierfür nutzen wir den colnames()-Befehl, der uns die Spaltennamen anzeigt. Im nächsten Schritt speichern wir einen 2. Datensatz, in dem die Variablen, die uns nicht interessieren (z.B. die IDs in SosciSurvey, die benötige Zeit, etc.) herauslöschen. Wir wählen hier die Proband:innen-Nummer, die demografischen Variablen (fangen alle mit “EI” an), die Items unseres Fragebogens (fangen alle mit “K” an) und die erwartete Verfügbarkeit in der Freundesgruppe (“VE01”) aus, ihr solltet in eurer Arbeit alle Variablen auswählen, die wichtig für eure Auswertung sind. Wenn ihr kein Muster in der Benennung der Variablennamen habt (also EI bzw. K), könnt ihr auch die Ergebnisse des colnames()-Befehls nutzen.\n\ncolnames(data_roh)\n\n [1] \"CASE\"     \"SERIAL\"   \"REF\"      \"QUESTNNR\" \"MODE\"     \"STARTED\" \n [7] \"EI05\"     \"EI01\"     \"EI02_01\"  \"K101_01\"  \"K101_02\"  \"K101_03\" \n[13] \"K101_04\"  \"K101_06\"  \"K101_08\"  \"K101_09\"  \"K101_10\"  \"K101_05\" \n[19] \"K101_11\"  \"K201_01\"  \"K201_02\"  \"K201_03\"  \"K201_05\"  \"K201_06\" \n[25] \"K301_01\"  \"K301_02\"  \"K301_03\"  \"K301_04\"  \"K301_05\"  \"K301_06\" \n[31] \"K301_07\"  \"K301_08\"  \"K301_09\"  \"K401_01\"  \"K401_06\"  \"K401_02\" \n[37] \"K401_03\"  \"K401_04\"  \"K401_05\"  \"K501_01\"  \"K501_06\"  \"K501_03\" \n[43] \"K501_04\"  \"K501_05\"  \"TIME001\"  \"TIME002\"  \"TIME003\"  \"TIME004\" \n[49] \"TIME005\"  \"TIME006\"  \"TIME007\"  \"TIME008\"  \"TIME_SUM\" \"MAILSENT\"\n[55] \"LASTDATA\" \"STATUS\"   \"FINISHED\" \"Q_VIEWER\" \"LASTPAGE\" \"MAXPAGE\" \n[61] \"MISSING\"  \"MISSREL\"  \"TIME_RSI\" \"VE01\"    \n\n\n\nMöglichkeit 1Möglichkeit 2\n\n\nWir können einerseits die Spalten direkt mit ihrem Namen ansprechen und auswählen:\n\nsel_vars &lt;- c('CASE', 'EI05', 'EI01', 'EI02_01', 'K101_01', 'K101_02', 'K101_03', 'K101_04', 'K101_06', 'K101_08', 'K101_09', 'K101_10', 'K101_05', 'K101_11', 'K201_01', 'K201_02', 'K201_03', 'K201_05', 'K201_06', 'K301_01', 'K301_02', 'K301_03', 'K301_04', 'K301_05', 'K301_06', 'K301_07', 'K301_08', 'K301_09', 'K401_01', 'K401_06', 'K401_02', 'K401_03', 'K401_04', 'K401_05', 'K501_01', 'K501_06', 'K501_03', 'K501_04', 'K501_05', 'VE01')\n\ndata_brauchbar &lt;- data_roh[, sel_vars]\n\n\n\nAlternativ können Spalten auch über ihren Index (steht bei dem Output von colnames() links) auswählen.\n\nsel_vars &lt;- c(1, 7:44, 64)\ndata_brauchbar &lt;- data_roh[, sel_vars] \n\n\n\n\nIm nächsten Schritt wollen wir die Variablen so umbenennen, dass wir sie im nächsten Schritt einfacher nutzen können. Die notwendige Informationen sind im Codebook enthalten, welches ihr ebenfalls bei SosciSurvey herunterladen könnt. Es macht Sinn, die Namen auch inhaltlich zu benennen, in unserem Beispiel geht es um FOMO (Fear of missing out)\n\nMöglichkeit 1Möglichkeit 2\n\n\nWir können einerseits mit dem rename(newname = oldname)-Befehl des dplyr-Pakets einzeln Spalten umbennen.\n\ndata_brauchbar &lt;- data_brauchbar %&gt;%\n  rename(\n    id = CASE, zustimmung = EI05, geschlecht = EI01, alter = EI02_01,\n    fomo1 = K101_01, fomo2 = K101_02,  fomo3 = K101_03, # ...\n    # jede Variable, die geändert werden soll, hier einfügen\n  ) \n\n\n\nWir können die Spalten auch gleichzeitig umbennen mit dem colnames()-Befehl. Dabei machen wir uns zu Nutze, dass die Spaltennamen für FOMO fomo1, fomo2, fomo3, … bennant werden sollen und wir dadurch durch den paste0(\"fomo\", seq(1, 35)) die 35 Variablennamen mit einem Befehl erstellen können. Die Reihenfolge der neuen Spaltennamen muss der Reihenfolge der alten Spaltennamen entsprechen.\n\n## Neue Spaltennamen:\ncolnames(data_brauchbar) &lt;- c(\n  \"id\", \"zustimmung\", \"geschlecht\", \"alter\", \n  paste0(\"fomo\", seq(1, 35)), \"verfuegbarkeitserwartung\"\n  )\n\n\n\n\nNun interessiert es uns, ob es fehlende Werte gibt. Dies kann man mit dem anyNA()-Befehl erfragen. Allerdings gibt es hier eine Schwierigkeiten, da SosciSurvey fehlende Werte nicht als NA sondern als -1 bzw. -9 speichert. Aus diesem Grund müssen wir festlegen, dass -1 und -9 als NAs angesehen werden.\n\n## Abfrage, ob NAs vorhanden sind:\nanyNA(data_brauchbar) # FALSE \n\n[1] FALSE\n\n## Abfrage, ob -1 oder -9 vorhanden ist:\nany(data_brauchbar == -9) # TRUE\n\n[1] TRUE\n\nany(data_brauchbar == -1) # TRUE\n\n[1] TRUE\n\n## Da diese fehlenden Werte vorhanden sind, müssen diese als NAs gelabelt werden:\ndata_brauchbar[data_brauchbar == -9] &lt;- NA\ndata_brauchbar[data_brauchbar == -1] &lt;- NA\n\n## Abfrage, ob es nun NAs gibt:\nanyNA(data_brauchbar) # TRUE -&gt; das Umlabeln hat also funktioniert \n\n[1] TRUE\n\n## Wie viele Daten fehlen:\nsum(is.na(data_brauchbar)) # 95 fehlende Angaben\n\n[1] 95\n\n\nIn diesem Fall sind 95 fehlende Werte vorhanden. Um die fehlenden Werte genauer zu explorieren, sollte am Rande das naniar-Package erwähnt werden, da es einige nützliche Funktionen diesbezüglich enthält. Wir können zum Beispiel über die Cases (Proband:innen) hinweg die prozentuale Häufigkeit an Missings berechnen.\n\nna_count_per_person &lt;- miss_case_summary(data_brauchbar) %&gt;% \nfilter(pct_miss &gt; 0) # nur Personen die NAs haben \n\nprint(na_count_per_person)\n\n\n\n\nAnzahl an NAs pro Person\n\n\ncase\nn_miss\npct_miss\n\n\n\n\n35\n35\n87.5\n\n\n89\n35\n87.5\n\n\n32\n5\n12.5\n\n\n71\n3\n7.5\n\n\n69\n2\n5.0\n\n\n97\n2\n5.0\n\n\n7\n1\n2.5\n\n\n17\n1\n2.5\n\n\n21\n1\n2.5\n\n\n56\n1\n2.5\n\n\n68\n1\n2.5\n\n\n81\n1\n2.5\n\n\n94\n1\n2.5\n\n\n102\n1\n2.5\n\n\n104\n1\n2.5\n\n\n127\n1\n2.5\n\n\n133\n1\n2.5\n\n\n139\n1\n2.5\n\n\n148\n1\n2.5\n\n\n\n\n\nHier sehen wir nun, dass 2 Proband:innen 35 Items nicht beantwortet haben und 17 Personen mind. 1 NA haben. Die 19 Personen sollen aufgrund der Einfachheit mit na.omit() ausgeschlossen werden.\n\n\n\n\n\n\nDisclaimer zu fehlenden Werten\n\n\n\nEs sollte zumindest am Rande erwähnt werden, dass die Funktion na.omit() sehr mächtig ist und nur mit Vorsicht verwendet werden sollte. Ohne weitere Überlegungen NAs auszuschließen, deren Fehlen möglicherweise nicht zufällig ist, sondern durch andere (nicht)-erhobene Variablen bedingt sind, kann zu Verzerrungen führen.\nFür dieses Seminar ist es aber in Ordnung Personen mit fehlenden Werten auszuschließen. Falls ihr euch mehr mit dem Thema NAs auseinandersetzen wollt, hier ein spannender Blogpost.\n\n\n\ndata_ohneNA &lt;- na.omit(data_brauchbar) # NAs auschließen\n\n\n\nDatenaufbereitung\nIn diesem Abschnitt wird der Datensatz Schritt für Schritt für unsere Analysen vorbereitet. Zuerst wird die Variable Geschlecht (geschlecht), die standardmäßig von SosciSurvey aus Zahlen 1 bis 3 beinhaltet, in eine verständlichere Form umgewandelt: Die Zahlen stehen jetzt für “m” (männlich), “w” (weiblich) und “d” (divers). Die Reihenfolge in der die Geschlechter durchnummeriert sind, hängt von eurer Erhebung ab. Ihr könnt diese im Codebook nachschauen.\nDie Variable “Erwartung der Verfuegbarkeit” (verfuegbarkeitserwartung) beinhaltet inwieweit die eigene Freundesgruppe erwartet, dass man schnell antwortet und für Ihre Anliegen und Probleme verfügbar ist. Diese Variable muss ebenfalls als analog zum Geschlecht als Faktor umkodiert werden.\n\n# Geschlecht:\ntable(data_ohneNA$geschlecht)\n\n\n  1   2   3 \n 32 103   1 \n\n# Umwandlung in Faktor\ndata_ohneNA$geschlecht &lt;- factor(\n  x = data_ohneNA$geschlecht, # Variable auswählen \n  levels = 1:3, # 3 Geschlechter erhoben\n  labels = c(\"m\", \"w\", \"d\") # Reihenfolge wie auch erhoben wurde\n  ) \n\ntable(data_ohneNA$geschlecht)\n\n\n  m   w   d \n 32 103   1 \n\n# Verfuegbarkeitserwartung:\ntable(data_ohneNA$verfuegbarkeitserwartung)\n\n\n   hoch  mittel niedrig \n     39      60      37 \n\n# Umwandlung in Faktor\ndata_ohneNA$verfuegbarkeitserwartung &lt;- factor(\n  x = data_ohneNA$verfuegbarkeitserwartung,\n  levels = c(\"niedrig\", \"mittel\", \"hoch\"),\n  labels = c(\"niedrig\", \"mittel\", \"hoch\")\n  )\n\ntable(data_ohneNA$verfuegbarkeitserwartung)\n\n\nniedrig  mittel    hoch \n     37      60      39 \n\n\nBevor wir einen summierten FOMO-Wert berechnen können, müssen wir im Codebook schauen, ob es invertierte Items gibt, d.h. Fragen bei denen hohe Werte (entgegen des inhaltlichen Zusammenhangs) für weniger FOMO spricht. Dies ist für die Items 10, 24, 29, 30, 32 der Fall. Wir können diese Items mit dem rec(..., rec = \"rev\") Befehl des sjmisc-Paket sehr einfach invertieren.\n\n# Invertierte Items umkodieren (1 &lt;-&gt; 4, 2 &lt;-&gt; 3 entspricht: 5 - Wert)\n\ndata_ohneNA$fomo10_inv &lt;- rec(data_ohneNA$fomo10, rec = \"rev\")\ndata_ohneNA$fomo24_inv &lt;- rec(data_ohneNA$fomo24, rec = \"rev\")\ndata_ohneNA$fomo29_inv &lt;- rec(data_ohneNA$fomo29, rec = \"rev\")\ndata_ohneNA$fomo30_inv &lt;- rec(data_ohneNA$fomo30, rec = \"rev\")\ndata_ohneNA$fomo32_inv &lt;- rec(data_ohneNA$fomo32, rec = \"rev\")\n\nDanach können wir einen Gesamtmittelwert “FOMO” für jede Person berechnen, wofür wir den rowMeans()-Befehl nutzen.\n\n# Liste der Items (inkl. invertierter Items)\nfomo_items &lt;- c(\n  paste0(\"fomo\", 1:9),\n  \"fomo10_inv\",\n  paste0(\"fomo\", 11:23),\n  \"fomo24_inv\",\n  paste0(\"fomo\", 25:28),\n  \"fomo29_inv\",\n  \"fomo30_inv\",\n  \"fomo31\",\n  \"fomo32_inv\",\n  paste0(\"fomo\", 33:35)\n)\n\n# Mittelwert berechnen\ndata_ohneNA$fomo &lt;- rowMeans(data_ohneNA[, fomo_items])\nhead(data_ohneNA$fomo)\n\n[1] 2.714286 2.914286 2.228571 2.200000 2.257143 1.857143\n\n\n\n\nExportieren des Datensatzes\nAbschließend exportieren wir unseren aufbereiteten Datensatz, damit wir im nächsten Skript weiter damit arbeiten können und tatsächliche deskriptive und inferenzstatistische Analysen durchführen können. Wählt hier einen Ort auf euerem PC und Dateinamen aus, sodass ihr die Datei wiederfindet.\n\nwrite_csv(data_ohneNA, \"data/proc/daten_fomo_processed.csv\")\n\n\n\nVerwendete Pakete\n\nsessioninfo::session_info(pkgs = \"attached\")\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.5.2 (2025-10-31)\n os       macOS Tahoe 26.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Berlin\n date     2025-12-08\n pandoc   3.1.12.3 @ /opt/homebrew/bin/ (via rmarkdown)\n quarto   1.7.32 @ /Applications/quarto/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package    * version date (UTC) lib source\n dplyr      * 1.1.4   2023-11-17 [1] CRAN (R 4.5.0)\n kableExtra * 1.4.0   2024-01-24 [1] CRAN (R 4.5.0)\n naniar     * 1.1.0   2024-03-05 [1] CRAN (R 4.5.0)\n psych      * 2.5.6   2025-06-23 [1] CRAN (R 4.5.0)\n readr      * 2.1.6   2025-11-14 [1] CRAN (R 4.5.2)\n sjmisc     * 2.8.11  2025-07-30 [1] CRAN (R 4.5.0)\n\n [1] /Users/luca/Library/R/arm64/4.5/library\n [2] /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library\n * ── Packages attached to the search path.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EW-BA6",
    "section": "",
    "text": "Willkommen. Diese Webseite bündelt die R-Skripte für die statistische Auswertung Ihres Forschungsprojekts für das Seminar EW-BA6."
  },
  {
    "objectID": "index.html#übersicht",
    "href": "index.html#übersicht",
    "title": "EW-BA6",
    "section": "Übersicht",
    "text": "Übersicht\nDer Ablauf der Auswertung gliedert sich in zwei aufeinanderfolgende Schritte:\n\nDatenaufbereitung: Import von SoSciSurvey, Bereinigung fehlender Werte und Skalenbildung.\nStatistische Analyse: Deskriptive Statistik und Hypothesentests (t-Test, ANOVA, Korrelation)."
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "EW-BA6",
    "section": "Setup",
    "text": "Setup\nDamit Sie die Skripte nutzen können, muss Ihre Arbeitsumgebung korrekt eingerichtet sein. Bitte arbeiten Sie diese vier Punkte nacheinander ab:\n\nR Installation\nRStudio Desktop Installation\nR-Pakete installieren\nRohdaten ablegen\n\n\n\n\n\n\n\nKlick hier: Schritt-für-Schritt Installationsanleitung\n\n\n\n\n\nWichtig: Installieren Sie zwingend zuerst R, danach RStudio.\nZu Schritt 1: R installieren\n\nWindows: Download hier\nmacOS: Download hier\n\nAchtung: Wählen Sie die richtige Version für Ihren Chip!\n“Apple Silicon” (M1/M2/M3) \\(\\rightarrow\\) arm64 Datei.\nAlter Intel-Mac \\(\\rightarrow\\) x86_64 Datei.\n\n\nZu Schritt 2: RStudio installieren\n\nLaden Sie die kostenlose “RStudio Desktop” Version hier herunter.\n\nZu Schritt 3: Pakete installieren\nKopieren Sie diesen Code, fügen Sie ihn in die Konsole von RStudio ein und drücken Sie Enter:\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(readr, dplyr, rstatix, sjPlot, systemfonts, tidyplots, naniar, psych, sjmisc)\nZu Schritt 4: Rohdaten\nLaden Sie den Datensatz hier herunter: Datensatz (CSV) downloaden.\n\nErstellen Sie in Ihrem Projektordner die Unterordner data und darin raw (data/raw).\nVerschieben Sie die Datei mit den Rohdaten genau dort hinein."
  }
]